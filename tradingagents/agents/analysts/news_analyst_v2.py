"""
æ–°é—»åˆ†æå¸ˆ (LangChain 1.0 ç‰ˆæœ¬)

ä½¿ç”¨ LangChain 1.0 çš„ create_agent API é‡æ„
- è‡ªåŠ¨å·¥å…·å¾ªç¯ï¼ˆReActæ¨¡å¼ï¼‰
- ç»“æ„åŒ–è¾“å‡ºï¼ˆNewsAnalysis Pydanticæ¨¡å‹ï¼‰
- ç»Ÿä¸€æ–°é—»è·å–ï¼ˆæ”¯æŒAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰
- ç§»é™¤ç‰¹æ®ŠLLMå¤„ç†é€»è¾‘ï¼ˆcreate_agent è‡ªåŠ¨å¤„ç†ï¼‰
"""

from datetime import date, datetime, timedelta
from typing import Annotated

from langchain import create_agent
from langchain_core.tools import tool
from langchain_core.messages import BaseMessage

# å¯¼å…¥ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
from tradingagents.models.analyst_outputs import NewsAnalysis

# å¯¼å…¥æ•°æ®æ¥å£
import tradingagents.dataflows.interface as interface

# å¯¼å…¥æ—¥å¿—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('analysts.news')


# ============================================
# å®šä¹‰å·¥å…·ï¼ˆToolsï¼‰
# ============================================

@tool
def get_stock_news(
    ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 000001, 600519, AAPL"],
    days: Annotated[int, "è·å–æœ€è¿‘Nå¤©çš„æ–°é—»"] = 7,
    max_news: Annotated[int, "æœ€å¤šè¿”å›Næ¡æ–°é—»"] = 10
) -> str:
    """
    è·å–è‚¡ç¥¨çš„æœ€æ–°æ–°é—»ï¼Œè‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ï¼‰

    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        days: æŸ¥è¯¢å¤©æ•°ï¼Œé»˜è®¤7å¤©
        max_news: æœ€å¤šè¿”å›çš„æ–°é—»æ•°é‡

    Returns:
        æ ¼å¼åŒ–çš„æ–°é—»åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ—¶é—´ã€æ¥æºã€æ‘˜è¦ç­‰
    """
    logger.info(f"ğŸ“° [å·¥å…·è°ƒç”¨] get_stock_news(ticker={ticker}, days={days}, max_news={max_news})")

    try:
        # è‡ªåŠ¨è¯†åˆ«å¸‚åœºç±»å‹
        from tradingagents.utils.stock_utils import StockUtils
        market_info = StockUtils.get_market_info(ticker)

        logger.info(f"ğŸ“Š [å·¥å…·è°ƒç”¨] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        news_result = None

        if market_info['is_china']:
            # ä¸­å›½Aè‚¡æ–°é—»
            logger.info(f"ğŸ“° [å·¥å…·è°ƒç”¨] è·å–ä¸­å›½Aè‚¡æ–°é—»: {ticker}")
            news_result = interface.get_china_stock_news(
                ticker,
                start_date.strftime("%Y-%m-%d"),
                max_news
            )

        elif market_info['is_hk']:
            # æ¸¯è‚¡æ–°é—»
            logger.info(f"ğŸ“° [å·¥å…·è°ƒç”¨] è·å–æ¸¯è‚¡æ–°é—»: {ticker}")
            news_result = interface.get_hk_stock_news(
                ticker,
                days=days,
                max_news=max_news
            )

        elif market_info['is_us']:
            # ç¾è‚¡æ–°é—»
            logger.info(f"ğŸ“° [å·¥å…·è°ƒç”¨] è·å–ç¾è‚¡æ–°é—»: {ticker}")
            news_result = interface.get_finnhub_news(
                ticker,
                end_date.strftime("%Y-%m-%d"),
                days
            )

        else:
            return f"ä¸æ”¯æŒçš„è‚¡ç¥¨ç±»å‹: {ticker}"

        if not news_result or "æ— ç›¸å…³æ–°é—»" in str(news_result):
            return f"æœªæ‰¾åˆ°{ticker}åœ¨æœ€è¿‘{days}å¤©çš„æ–°é—»ï¼Œå¯èƒ½å¸‚åœºä¼‘å¸‚æˆ–è¯¥è‚¡ç¥¨å…³æ³¨åº¦è¾ƒä½"

        logger.info(f"âœ… [å·¥å…·è°ƒç”¨] æˆåŠŸè·å– {ticker} çš„æ–°é—»ï¼Œè¿”å›é•¿åº¦: {len(news_result)} å­—ç¬¦")
        return news_result

    except Exception as e:
        logger.error(f"âŒ [å·¥å…·è°ƒç”¨] get_stock_news å¤±è´¥: {e}")
        return f"è·å–æ–°é—»å¤±è´¥: {str(e)}"


@tool
def get_company_announcements(
    ticker: Annotated[str, "è‚¡ç¥¨ä»£ç "],
    days: Annotated[int, "è·å–æœ€è¿‘Nå¤©çš„å…¬å‘Š"] = 30
) -> str:
    """
    è·å–å…¬å¸çš„å®˜æ–¹å…¬å‘Šï¼ˆä»…æ”¯æŒAè‚¡ï¼‰

    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        days: æŸ¥è¯¢å¤©æ•°

    Returns:
        æ ¼å¼åŒ–çš„å…¬å‘Šåˆ—è¡¨
    """
    logger.info(f"ğŸ“‹ [å·¥å…·è°ƒç”¨] get_company_announcements(ticker={ticker}, days={days})")

    try:
        from tradingagents.utils.stock_utils import StockUtils
        market_info = StockUtils.get_market_info(ticker)

        if not market_info['is_china']:
            return "å…¬å¸å…¬å‘ŠåŠŸèƒ½ä»…æ”¯æŒä¸­å›½Aè‚¡"

        # è·å–å…¬å‘Š
        announcements = interface.get_company_announcements(ticker, days)

        if not announcements:
            return f"æœªæ‰¾åˆ°{ticker}åœ¨æœ€è¿‘{days}å¤©çš„å…¬å‘Š"

        logger.info(f"âœ… [å·¥å…·è°ƒç”¨] æˆåŠŸè·å– {ticker} çš„å…¬å‘Š")
        return announcements

    except Exception as e:
        logger.error(f"âŒ [å·¥å…·è°ƒç”¨] get_company_announcements å¤±è´¥: {e}")
        return f"è·å–å…¬å‘Šå¤±è´¥: {str(e)}"


@tool
def search_related_news(
    keyword: Annotated[str, "æœç´¢å…³é”®è¯ï¼Œå¦‚'æ–°èƒ½æº'ã€'èŠ¯ç‰‡'ã€'æ”¿ç­–'"],
    days: Annotated[int, "æœç´¢æœ€è¿‘Nå¤©çš„æ–°é—»"] = 7,
    max_news: Annotated[int, "æœ€å¤šè¿”å›Næ¡æ–°é—»"] = 5
) -> str:
    """
    æœç´¢ç›¸å…³è¡Œä¸šæˆ–ä¸»é¢˜çš„æ–°é—»

    Args:
        keyword: æœç´¢å…³é”®è¯
        days: æŸ¥è¯¢å¤©æ•°
        max_news: æœ€å¤šè¿”å›çš„æ–°é—»æ•°é‡

    Returns:
        ç›¸å…³æ–°é—»åˆ—è¡¨
    """
    logger.info(f"ğŸ” [å·¥å…·è°ƒç”¨] search_related_news(keyword={keyword}, days={days})")

    try:
        # æœç´¢ç›¸å…³æ–°é—»
        news = interface.search_industry_news(keyword, days, max_news)

        if not news:
            return f"æœªæ‰¾åˆ°ä¸'{keyword}'ç›¸å…³çš„æ–°é—»"

        logger.info(f"âœ… [å·¥å…·è°ƒç”¨] æˆåŠŸæœç´¢åˆ° {keyword} ç›¸å…³æ–°é—»")
        return news

    except Exception as e:
        logger.error(f"âŒ [å·¥å…·è°ƒç”¨] search_related_news å¤±è´¥: {e}")
        return f"æœç´¢æ–°é—»å¤±è´¥: {str(e)}"


# ============================================
# åˆ›å»ºæ–°é—»åˆ†æå¸ˆ Agent
# ============================================

def create_news_analyst_v2(llm, config: dict = None):
    """
    ä½¿ç”¨ LangChain 1.0 create_agent åˆ›å»ºæ–°é—»åˆ†æå¸ˆ

    Args:
        llm: LLM å®ä¾‹
        config: é…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰

    Returns:
        æ–°é—»åˆ†æå¸ˆ agent
    """

    logger.info("ğŸš€ [LangChain 1.0] åˆ›å»ºæ–°é—»åˆ†æå¸ˆ (ä½¿ç”¨ create_agent)")

    # å®šä¹‰å·¥å…·åˆ—è¡¨
    tools = [
        get_stock_news,
        get_company_announcements,
        search_related_news,
    ]

    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è´¢ç»æ–°é—»åˆ†æå¸ˆï¼Œè´Ÿè´£åˆ†ææœ€æ–°çš„å¸‚åœºæ–°é—»å’Œäº‹ä»¶å¯¹è‚¡ç¥¨ä»·æ ¼çš„æ½œåœ¨å½±å“ã€‚

ä½ çš„åˆ†ææµç¨‹ï¼š
1. **è·å–è‚¡ç¥¨æ–°é—»** - ä½¿ç”¨ get_stock_news è·å–æœ€æ–°æ–°é—»ï¼ˆé»˜è®¤7å¤©ï¼‰
2. **è·å–å…¬å¸å…¬å‘Š** - å¦‚æœæ˜¯Aè‚¡ï¼Œè·å–å®˜æ–¹å…¬å‘Š
3. **æœç´¢ç›¸å…³è¡Œä¸šæ–°é—»** - äº†è§£è¡Œä¸šæ•´ä½“åŠ¨æ€
4. **ç»¼åˆåˆ†æ** - åŸºäºä»¥ä¸Šä¿¡æ¯ç»™å‡ºæŠ•èµ„å»ºè®®

é‡ç‚¹å…³æ³¨çš„æ–°é—»ç±»å‹ï¼š
- ğŸ“Š **è´¢æŠ¥å‘å¸ƒ**: ä¸šç»©è¶…é¢„æœŸ/ä½äºé¢„æœŸçš„å½±å“
- ğŸ¤ **é‡å¤§åˆä½œ**: å¹¶è´­ã€æˆ˜ç•¥åˆä½œã€æŠ€æœ¯æˆæƒ
- ğŸ“œ **æ”¿ç­–å˜åŒ–**: ç›‘ç®¡æ”¿ç­–ã€è¡Œä¸šæ”¿ç­–ã€ç¨æ”¶æ”¿ç­–
- ğŸš¨ **çªå‘äº‹ä»¶**: å±æœºç®¡ç†ã€è´Ÿé¢æ–°é—»ã€è¯‰è®¼çº çº·
- ğŸ­ **è¡Œä¸šè¶‹åŠ¿**: æŠ€æœ¯çªç ´ã€å¸‚åœºæ ¼å±€å˜åŒ–
- ğŸ‘” **ç®¡ç†å±‚å˜åŠ¨**: é«˜ç®¡ä»»å…ã€æˆ˜ç•¥è°ƒæ•´

åˆ†æè¦ç‚¹ï¼š
- â° **æ—¶æ•ˆæ€§**: ä¼˜å…ˆåˆ†ææœ€æ–°æ–°é—»ï¼ˆ24å°æ—¶å†…ï¼‰
- ğŸ” **å¯ä¿¡åº¦**: æƒå¨åª’ä½“ > ä¸€èˆ¬åª’ä½“
- ğŸ“ˆ **å½±å“ç¨‹åº¦**: è¯„ä¼°å¯¹è‚¡ä»·çš„çŸ­æœŸå’Œé•¿æœŸå½±å“
- ğŸ˜Š **æƒ…ç»ªåˆ¤æ–­**: æ­£é¢/ä¸­æ€§/è´Ÿé¢
- ğŸ“Š **å†å²å¯¹æ¯”**: ä¸ç±»ä¼¼äº‹ä»¶çš„å¸‚åœºååº”å¯¹æ¯”

æ–°é—»å½±å“åˆ†ææ ‡å‡†ï¼š
- **éå¸¸æ­£é¢**: é‡å¤§åˆ©å¥½æ¶ˆæ¯ï¼Œé¢„æœŸçŸ­æœŸå¤§æ¶¨
- **æ­£é¢**: ä¸€èˆ¬åˆ©å¥½ï¼Œé¢„æœŸæ¸©å’Œä¸Šæ¶¨
- **ä¸­æ€§**: ä¿¡æ¯æ€§æ–°é—»ï¼Œæ— æ˜æ˜¾å½±å“
- **è´Ÿé¢**: ä¸€èˆ¬åˆ©ç©ºï¼Œé¢„æœŸä¸‹è·Œ
- **éå¸¸è´Ÿé¢**: é‡å¤§åˆ©ç©ºï¼Œé¢„æœŸå¤§è·Œ

æŠ•èµ„å»ºè®®æ ‡å‡†ï¼š
- **å¼ºçƒˆä¹°å…¥**: é‡å¤§åˆ©å¥½ + é«˜ç½®ä¿¡åº¦ > 0.85
- **ä¹°å…¥**: æ­£é¢æ–°é—» + ç½®ä¿¡åº¦ 0.70-0.85
- **æŒæœ‰**: ä¸­æ€§æ–°é—» + ç½®ä¿¡åº¦ 0.50-0.70
- **å–å‡º**: è´Ÿé¢æ–°é—» + ç½®ä¿¡åº¦ 0.70-0.85
- **å¼ºçƒˆå–å‡º**: é‡å¤§åˆ©ç©º + é«˜ç½®ä¿¡åº¦ > 0.85

æ³¨æ„äº‹é¡¹ï¼š
- å¿…é¡»åŸºäºçœŸå®æ–°é—»æ•°æ®ï¼Œä¸è¦ç¼–é€ 
- æ˜ç¡®è¯´æ˜æ–°é—»æ¥æºå’Œæ—¶é—´
- è¯šå®è¯„ä¼°ç½®ä¿¡åº¦
- è¯†åˆ«ä¸»è¦é£é™©å› ç´ 
- å¦‚æœæ–°é—»è¾ƒå°‘æˆ–æ»åï¼Œåœ¨åˆ†æä¸­è¯´æ˜

ä»Šå¤©çš„æ—¥æœŸæ˜¯: {current_date}
"""

    # ğŸ‰ LangChain 1.0 æ ¸å¿ƒï¼šcreate_agent
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=system_prompt.format(
            current_date=date.today().strftime("%Y-%m-%d")
        ),
        # ğŸ‰ ç»“æ„åŒ–è¾“å‡ºï¼šè‡ªåŠ¨éªŒè¯å’Œç±»å‹å®‰å…¨
        structured_output=NewsAnalysis,
    )

    logger.info("âœ… [LangChain 1.0] æ–°é—»åˆ†æå¸ˆåˆ›å»ºæˆåŠŸ")

    return agent


# ============================================
# ä¾¿æ·åŒ…è£…å‡½æ•°ï¼ˆå…¼å®¹æ—§APIï¼‰
# ============================================

def create_news_analyst_node_v2(llm, toolkit=None):
    """
    åˆ›å»ºæ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹ï¼ˆå…¼å®¹ LangGraph çš„æ—§ APIï¼‰

    Args:
        llm: LLM å®ä¾‹
        toolkit: å·¥å…·é›†ï¼ˆä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œå®é™…ä¸ä½¿ç”¨ï¼‰

    Returns:
        news_analyst_node å‡½æ•°
    """

    # åˆ›å»º agent
    agent = create_news_analyst_v2(llm)

    def news_analyst_node(state):
        """
        æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹

        Args:
            state: LangGraph çŠ¶æ€å¯¹è±¡

        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        logger.info("ğŸ“° [æ–°é—»åˆ†æå¸ˆèŠ‚ç‚¹] å¼€å§‹åˆ†æ")

        try:
            # ä»çŠ¶æ€ä¸­æå–æ¶ˆæ¯
            messages = state.get("messages", [])

            # ğŸ‰ è°ƒç”¨ agentï¼ˆè‡ªåŠ¨å·¥å…·å¾ªç¯ + ç»“æ„åŒ–è¾“å‡ºï¼‰
            result: NewsAnalysis = agent.invoke({"messages": messages})

            logger.info(f"âœ… [æ–°é—»åˆ†æå¸ˆ] åˆ†æå®Œæˆ")
            logger.info(f"   è‚¡ç¥¨: {result.ticker} ({result.company_name})")
            logger.info(f"   æ–°é—»æ•°é‡: {result.news_count}")
            logger.info(f"   æƒ…ç»ª: {result.sentiment}")
            logger.info(f"   å»ºè®®: {result.recommendation}")
            logger.info(f"   ç½®ä¿¡åº¦: {result.confidence:.0%}")

            # æ ¼å¼åŒ–ä¸ºæ¶ˆæ¯ï¼ˆå…¼å®¹æ—§APIï¼‰
            from langchain_core.messages import AIMessage

            formatted_message = AIMessage(
                content=f"""## ğŸ“° æ–°é—»æƒ…ç»ªåˆ†æ

**è‚¡ç¥¨**: {result.company_name} ({result.ticker})
**åˆ†ææ—¥æœŸ**: {result.analysis_date}
**æ–°é—»æ•°é‡**: {result.news_count} æ¡

### ğŸ“Š æƒ…ç»ªåˆ†æ
- **æ•´ä½“æƒ…ç»ª**: {result.sentiment}
- **æƒ…ç»ªå¾—åˆ†**: {result.sentiment_score:.2f} (-1åˆ°1)
- **å½±å“è¯„ä¼°**: {result.impact_assessment}

### ğŸ“° å…³é”®æ–°é—»
{chr(10).join(f'{i+1}. {news}' for i, news in enumerate(result.key_news_summary))}

### ğŸ·ï¸ æ–°é—»ä¸»é¢˜
{', '.join(result.news_topics)}

### ğŸ¯ æŠ•èµ„å»ºè®®
- **å»ºè®®**: {result.recommendation}
- **ç½®ä¿¡åº¦**: {result.confidence:.0%}

### ğŸ’¡ åˆ†æç†ç”±
{result.reasoning}

### âš ï¸ é£é™©å› ç´ 
{chr(10).join(f'- {risk}' for risk in result.risk_factors)}
""",
                # ğŸ‰ é™„åŠ ç»“æ„åŒ–æ•°æ®ï¼ˆå¯ä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨ï¼‰
                additional_kwargs={
                    "structured_output": result.model_dump(),
                    "analyst_type": "news",
                }
            )

            return {"messages": [formatted_message]}

        except Exception as e:
            logger.error(f"âŒ [æ–°é—»åˆ†æå¸ˆ] åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            from langchain_core.messages import AIMessage
            error_message = AIMessage(
                content=f"æ–°é—»åˆ†æå¤±è´¥: {str(e)}"
            )
            return {"messages": [error_message]}

    return news_analyst_node


# ============================================
# ä»£ç ç»Ÿè®¡
# ============================================

"""
ğŸ“Š ä»£ç è¡Œæ•°å¯¹æ¯”ï¼š

æ—§ç‰ˆ (news_analyst.py):
- æ€»è¡Œæ•°: ~350 è¡Œ
- æ ¸å¿ƒé€»è¾‘: ~200 è¡Œ
- ç‰¹æ®ŠLLMå¤„ç†: ~100 è¡Œï¼ˆDashScope/DeepSeeké¢„å¤„ç†ï¼‰
- å·¥å…·å¾ªç¯: æ‰‹åŠ¨å®ç° ~50 è¡Œ

æ–°ç‰ˆ (news_analyst_v2.py):
- æ€»è¡Œæ•°: ~340 è¡Œï¼ˆåŒ…å«è¯¦ç»†æ³¨é‡Šå’Œæ–‡æ¡£ï¼‰
- æ ¸å¿ƒé€»è¾‘: ~50 è¡Œ
- ç‰¹æ®ŠLLMå¤„ç†: 0 è¡Œï¼ˆcreate_agent ç»Ÿä¸€å¤„ç†ï¼‰
- å·¥å…·å¾ªç¯: 0 è¡Œï¼ˆcreate_agent è‡ªåŠ¨å¤„ç†ï¼‰

ğŸ¯ æ”¹è¿›ï¼š
âœ… æ ¸å¿ƒä»£ç å‡å°‘ 75% (200è¡Œ â†’ 50è¡Œ)
âœ… ç§»é™¤æ‰€æœ‰ç‰¹æ®ŠLLMå¤„ç†é€»è¾‘ï¼ˆ100è¡Œ â†’ 0è¡Œï¼‰
âœ… å·¥å…·å¾ªç¯è‡ªåŠ¨åŒ–ï¼ˆæ— éœ€æ‰‹åŠ¨å®ç°ï¼‰
âœ… ç±»å‹å®‰å…¨ï¼ˆPydantic è‡ªåŠ¨éªŒè¯ï¼‰
âœ… æ›´å¥½çš„å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§
âœ… ç»“æ„åŒ–è¾“å‡ºï¼ˆå¯ç›´æ¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼‰
"""
