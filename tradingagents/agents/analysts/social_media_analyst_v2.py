"""
ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ (LangChain 1.0 ç‰ˆæœ¬)

ä½¿ç”¨ LangChain 1.0 çš„ create_agent API é‡æ„
- è‡ªåŠ¨å·¥å…·å¾ªç¯
- ç»“æ„åŒ–è¾“å‡ºï¼ˆSocialMediaAnalysis Pydanticæ¨¡å‹ï¼‰
- åˆ†ææŠ•èµ„è€…æƒ…ç»ªå’Œè®¨è®ºçƒ­åº¦
"""

from datetime import date
from typing import Annotated

from langchain import create_agent
from langchain_core.tools import tool

from tradingagents.models.analyst_outputs import SocialMediaAnalysis
import tradingagents.dataflows.interface as interface

from tradingagents.utils.logging_manager import get_logger
logger = get_logger('analysts.social_media')


# ============================================
# å·¥å…·å®šä¹‰
# ============================================

@tool
def get_reddit_sentiment(
    ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼Œä¸»è¦æ”¯æŒç¾è‚¡"],
    days: Annotated[int, "è·å–æœ€è¿‘Nå¤©çš„è®¨è®º"] = 7
) -> str:
    """è·å–Redditä¸Šå…³äºè¯¥è‚¡ç¥¨çš„è®¨è®ºå’Œæƒ…ç»ª"""
    logger.info(f"ğŸ—£ï¸ [å·¥å…·è°ƒç”¨] get_reddit_sentiment(ticker={ticker})")

    try:
        result = interface.get_reddit_company_news(ticker, days)
        if not result:
            return f"æœªæ‰¾åˆ°{ticker}åœ¨Redditä¸Šçš„è®¨è®º"
        logger.info(f"âœ… æˆåŠŸè·å–Redditæƒ…ç»ª")
        return result
    except Exception as e:
        logger.error(f"âŒ get_reddit_sentiment å¤±è´¥: {e}")
        return f"è·å–Redditæƒ…ç»ªå¤±è´¥: {str(e)}"


@tool
def get_chinese_social_sentiment(
    ticker: Annotated[str, "è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒAè‚¡ã€æ¸¯è‚¡"]
) -> str:
    """è·å–ä¸­å›½ç¤¾äº¤åª’ä½“ï¼ˆé›ªçƒã€ä¸œæ–¹è´¢å¯Œè‚¡å§ç­‰ï¼‰çš„æƒ…ç»ªåˆ†æ"""
    logger.info(f"ğŸ—£ï¸ [å·¥å…·è°ƒç”¨] get_chinese_social_sentiment(ticker={ticker})")

    try:
        result = interface.get_chinese_social_sentiment(ticker)
        if not result:
            return f"æœªæ‰¾åˆ°{ticker}åœ¨ä¸­å›½ç¤¾äº¤åª’ä½“çš„è®¨è®º"
        logger.info(f"âœ… æˆåŠŸè·å–ä¸­å›½ç¤¾äº¤åª’ä½“æƒ…ç»ª")
        return result
    except Exception as e:
        logger.error(f"âŒ get_chinese_social_sentiment å¤±è´¥: {e}")
        return f"è·å–ä¸­å›½ç¤¾äº¤åª’ä½“æƒ…ç»ªå¤±è´¥: {str(e)}"


@tool
def analyze_discussion_trends(
    ticker: Annotated[str, "è‚¡ç¥¨ä»£ç "]
) -> str:
    """åˆ†æè®¨è®ºçƒ­åº¦è¶‹åŠ¿ï¼ˆä¸Šå‡/å¹³ç¨³/ä¸‹é™ï¼‰"""
    logger.info(f"ğŸ“ˆ [å·¥å…·è°ƒç”¨] analyze_discussion_trends(ticker={ticker})")

    try:
        result = interface.get_discussion_trend_analysis(ticker)
        if not result:
            return f"æš‚æ— {ticker}çš„è®¨è®ºè¶‹åŠ¿æ•°æ®"
        logger.info(f"âœ… æˆåŠŸåˆ†æè®¨è®ºè¶‹åŠ¿")
        return result
    except Exception as e:
        logger.error(f"âŒ analyze_discussion_trends å¤±è´¥: {e}")
        return f"åˆ†æè®¨è®ºè¶‹åŠ¿å¤±è´¥: {str(e)}"


# ============================================
# åˆ›å»ºç¤¾äº¤åª’ä½“åˆ†æå¸ˆ Agent
# ============================================

def create_social_media_analyst_v2(llm, config: dict = None):
    """ä½¿ç”¨ LangChain 1.0 create_agent åˆ›å»ºç¤¾äº¤åª’ä½“åˆ†æå¸ˆ"""

    logger.info("ğŸš€ [LangChain 1.0] åˆ›å»ºç¤¾äº¤åª’ä½“åˆ†æå¸ˆ")

    tools = [
        get_reddit_sentiment,
        get_chinese_social_sentiment,
        analyze_discussion_trends,
    ]

    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æå¸ˆï¼Œä¸“æ³¨äºåˆ†ææŠ•èµ„è€…åœ¨ç¤¾äº¤å¹³å°ä¸Šçš„è®¨è®ºå’Œæƒ…ç»ªã€‚

åˆ†ææµç¨‹ï¼š
1. è·å–ç¤¾äº¤åª’ä½“è®¨è®ºæ•°æ®ï¼ˆRedditã€é›ªçƒã€è‚¡å§ç­‰ï¼‰
2. åˆ†æè®¨è®ºçƒ­åº¦å’Œè¶‹åŠ¿
3. è¯„ä¼°æ•´ä½“æƒ…ç»ªï¼ˆä¹è§‚/ä¸­æ€§/æ‚²è§‚ï¼‰
4. è¯†åˆ«å…³é”®è¯é¢˜å’Œå½±å“åŠ›è§‚ç‚¹
5. ç»™å‡ºåŸºäºç¤¾äº¤æƒ…ç»ªçš„æŠ•èµ„å»ºè®®

å…³æ³¨è¦ç‚¹ï¼š
- ğŸ“Š **è®¨è®ºçƒ­åº¦**: å¸–å­æ•°ã€è¯„è®ºæ•°ã€æµè§ˆé‡
- ğŸ˜Š **æƒ…ç»ªå€¾å‘**: æ­£é¢/ä¸­æ€§/è´Ÿé¢æ¯”ä¾‹
- ğŸ“ˆ **æƒ…ç»ªè¶‹åŠ¿**: è¿‘æœŸå˜åŒ–æ–¹å‘
- ğŸ”¥ **çƒ­é—¨è¯é¢˜**: æŠ•èµ„è€…å…³æ³¨çš„ç„¦ç‚¹
- ğŸ‘¥ **å½±å“åŠ›ç”¨æˆ·**: å¤§Vã€åˆ†æå¸ˆçš„è§‚ç‚¹

æƒ…ç»ªè¯„ä¼°æ ‡å‡†ï¼š
- **éå¸¸ä¹è§‚**: 90%+ æ­£é¢è®¨è®ºï¼Œçƒ­åº¦é«˜
- **ä¹è§‚**: 60-90% æ­£é¢è®¨è®º
- **ä¸­æ€§**: æ­£è´Ÿé¢åŸºæœ¬å‡è¡¡
- **æ‚²è§‚**: 60-90% è´Ÿé¢è®¨è®º
- **éå¸¸æ‚²è§‚**: 90%+ è´Ÿé¢è®¨è®ºï¼Œææ…Œæƒ…ç»ª

æŠ•èµ„å»ºè®®æ ‡å‡†ï¼š
- **å¼ºçƒˆä¹°å…¥**: æƒ…ç»ªæåº¦ä¹è§‚ + åŸºæœ¬é¢æ”¯æ’‘ (ç½®ä¿¡åº¦0.7-0.8)
- **ä¹°å…¥**: æƒ…ç»ªä¹è§‚ + è®¨è®ºçƒ­åº¦ä¸Šå‡ (ç½®ä¿¡åº¦0.6-0.7)
- **æŒæœ‰**: æƒ…ç»ªä¸­æ€§æˆ–åˆ†æ­§è¾ƒå¤§ (ç½®ä¿¡åº¦0.4-0.6)
- **å–å‡º**: æƒ…ç»ªæ‚²è§‚ + è´Ÿé¢è¯é¢˜å¤š (ç½®ä¿¡åº¦0.6-0.7)
- **å¼ºçƒˆå–å‡º**: ææ…Œæ€§æŠ›å”®è®¨è®º (ç½®ä¿¡åº¦0.7-0.8)

âš ï¸ æ³¨æ„ï¼š
- ç¤¾äº¤æƒ…ç»ªå¯èƒ½å­˜åœ¨ç¾Šç¾¤æ•ˆåº”å’Œæƒ…ç»ªæ³¢åŠ¨
- ä¸èƒ½å•ç‹¬ä¾èµ–ç¤¾äº¤æƒ…ç»ªåšå†³ç­–
- éœ€ç»“åˆåŸºæœ¬é¢å’ŒæŠ€æœ¯é¢ç»¼åˆåˆ¤æ–­
- ç½®ä¿¡åº¦é€šå¸¸ä½äºæŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†æ

ä»Šå¤©çš„æ—¥æœŸæ˜¯: {current_date}
"""

    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=system_prompt.format(current_date=date.today().strftime("%Y-%m-%d")),
        structured_output=SocialMediaAnalysis,
    )

    logger.info("âœ… ç¤¾äº¤åª’ä½“åˆ†æå¸ˆåˆ›å»ºæˆåŠŸ")
    return agent


def create_social_media_analyst_node_v2(llm, toolkit=None):
    """åˆ›å»ºç¤¾äº¤åª’ä½“åˆ†æå¸ˆèŠ‚ç‚¹ï¼ˆå…¼å®¹æ—§APIï¼‰"""

    agent = create_social_media_analyst_v2(llm)

    def social_media_analyst_node(state):
        logger.info("ğŸ—£ï¸ [ç¤¾äº¤åª’ä½“åˆ†æå¸ˆèŠ‚ç‚¹] å¼€å§‹åˆ†æ")

        try:
            messages = state.get("messages", [])
            result: SocialMediaAnalysis = agent.invoke({"messages": messages})

            logger.info(f"âœ… [ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ] åˆ†æå®Œæˆ")
            logger.info(f"   è‚¡ç¥¨: {result.ticker}")
            logger.info(f"   è®¨è®ºçƒ­åº¦: {result.discussion_volume}")
            logger.info(f"   æƒ…ç»ª: {result.sentiment}")
            logger.info(f"   å»ºè®®: {result.recommendation}")

            from langchain_core.messages import AIMessage

            formatted_message = AIMessage(
                content=f"""## ğŸ—£ï¸ ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ

**è‚¡ç¥¨**: {result.company_name} ({result.ticker})
**åˆ†ææ—¥æœŸ**: {result.analysis_date}

### ğŸ“Š ç¤¾äº¤åª’ä½“æŒ‡æ ‡
- **è®¨è®ºçƒ­åº¦**: {result.discussion_volume}
- **æŠ•èµ„è€…æƒ…ç»ª**: {result.sentiment}
- **æƒ…ç»ªè¶‹åŠ¿**: {result.sentiment_trend}

### ğŸ”¥ çƒ­é—¨è¯é¢˜
{chr(10).join(f'- {topic}' for topic in result.hot_topics)}

### ğŸ‘¥ å½±å“åŠ›è§‚ç‚¹
- **æ•´ä½“å€¾å‘**: {result.influencer_sentiment if result.influencer_sentiment else 'æœªåˆ†æ'}

### ğŸ¯ æŠ•èµ„å»ºè®®
- **å»ºè®®**: {result.recommendation}
- **ç½®ä¿¡åº¦**: {result.confidence:.0%}

### ğŸ’­ åˆ†æç†ç”±
{result.reasoning}

### âš ï¸ é£é™©æç¤º
{chr(10).join(f'- {risk}' for risk in result.risk_factors)}
""",
                additional_kwargs={
                    "structured_output": result.model_dump(),
                    "analyst_type": "social_media",
                }
            )

            return {"messages": [formatted_message]}

        except Exception as e:
            logger.error(f"âŒ [ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ] åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            from langchain_core.messages import AIMessage
            return {"messages": [AIMessage(content=f"ç¤¾äº¤åª’ä½“åˆ†æå¤±è´¥: {str(e)}")]}

    return social_media_analyst_node
