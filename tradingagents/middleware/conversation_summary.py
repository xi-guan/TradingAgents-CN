"""
å¯¹è¯æ€»ç»“ä¸­é—´ä»¶ (Conversation Summarization Middleware)

è‡ªåŠ¨å‹ç¼©é•¿å¯¹è¯å†å²ï¼Œå‡å°‘ token æ¶ˆè€—
"""

from typing import Dict, Any, List, Optional
from datetime import datetime

from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage

from tradingagents.middleware.base import BaseMiddleware, create_event, save_event_to_db
from tradingagents.utils.logging_manager import get_logger

logger = get_logger('middleware.conversation_summary')


class ConversationSummaryMiddleware(BaseMiddleware):
    """
    å¯¹è¯æ€»ç»“ä¸­é—´ä»¶

    åŠŸèƒ½ï¼š
    1. ç›‘æ§å¯¹è¯é•¿åº¦ï¼ˆæ¶ˆæ¯æ•°é‡æˆ– token æ•°ï¼‰
    2. è¾¾åˆ°é˜ˆå€¼æ—¶è‡ªåŠ¨è§¦å‘æ€»ç»“
    3. ä½¿ç”¨ LLM æ€»ç»“æ—§æ¶ˆæ¯
    4. ä¿ç•™æœ€è¿‘çš„é‡è¦æ¶ˆæ¯
    5. å‡å°‘ token æ¶ˆè€—
    """

    def __init__(
        self,
        llm = None,
        max_messages: int = 20,  # æœ€å¤šä¿ç•™20æ¡æ¶ˆæ¯
        max_tokens: Optional[int] = None,  # æˆ–æŒ‰ token æ•°é™åˆ¶
        keep_recent: int = 5,  # å§‹ç»ˆä¿ç•™æœ€è¿‘5æ¡æ¶ˆæ¯
        summarize_every: int = 10,  # æ¯10æ¡æ¶ˆæ¯è§¦å‘ä¸€æ¬¡æ€»ç»“
        db_connection = None
    ):
        """
        åˆå§‹åŒ–å¯¹è¯æ€»ç»“ä¸­é—´ä»¶

        Args:
            llm: ç”¨äºæ€»ç»“çš„ LLM å®ä¾‹
            max_messages: æœ€å¤šä¿ç•™çš„æ¶ˆæ¯æ•°
            max_tokens: æœ€å¤šä¿ç•™çš„ token æ•°ï¼ˆå¯é€‰ï¼‰
            keep_recent: å§‹ç»ˆä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
            summarize_every: æ¯Næ¡æ¶ˆæ¯è§¦å‘ä¸€æ¬¡æ€»ç»“
            db_connection: æ•°æ®åº“è¿æ¥
        """
        super().__init__(name="ConversationSummaryMiddleware")

        self.llm = llm
        self.max_messages = max_messages
        self.max_tokens = max_tokens
        self.keep_recent = keep_recent
        self.summarize_every = summarize_every
        self.db_connection = db_connection

        self.summarize_count = 0
        self.total_tokens_saved = 0

        logger.info(f"ğŸ“ [å¯¹è¯æ€»ç»“] åˆå§‹åŒ–")
        logger.info(f"   - æœ€å¤§æ¶ˆæ¯æ•°: {max_messages}")
        logger.info(f"   - ä¿ç•™æœ€è¿‘: {keep_recent} æ¡")
        logger.info(f"   - æ€»ç»“é¢‘ç‡: æ¯ {summarize_every} æ¡")

    def before_call(self, input_state: Dict[str, Any]) -> Dict[str, Any]:
        """
        åœ¨è°ƒç”¨å‰æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“

        Args:
            input_state: è¾“å…¥çŠ¶æ€

        Returns:
            å¤„ç†åçš„è¾“å…¥çŠ¶æ€
        """
        messages = input_state.get("messages", [])
        message_count = len(messages)

        logger.debug(f"ğŸ“Š [å¯¹è¯æ€»ç»“] å½“å‰æ¶ˆæ¯æ•°: {message_count}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ€»ç»“
        if message_count > self.max_messages:
            logger.info(f"ğŸ”„ [å¯¹è¯æ€»ç»“] æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ ({message_count} > {self.max_messages})ï¼Œå¼€å§‹æ€»ç»“")

            # æ‰§è¡Œæ€»ç»“
            summarized_messages = self._summarize_messages(messages)

            # æ›´æ–°çŠ¶æ€
            input_state["messages"] = summarized_messages
            input_state["conversation_summarized"] = True

            self.summarize_count += 1

            logger.info(f"âœ… [å¯¹è¯æ€»ç»“] æ€»ç»“å®Œæˆ: {message_count} â†’ {len(summarized_messages)} æ¡æ¶ˆæ¯")

        return input_state

    def _summarize_messages(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """
        æ€»ç»“æ¶ˆæ¯åˆ—è¡¨

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ€»ç»“åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if len(messages) <= self.keep_recent:
            logger.debug(f"ğŸ“Š [å¯¹è¯æ€»ç»“] æ¶ˆæ¯æ•°æœªè¶…è¿‡ä¿ç•™é˜ˆå€¼ï¼Œè·³è¿‡æ€»ç»“")
            return messages

        # åˆ†å‰²ï¼šéœ€è¦æ€»ç»“çš„æ—§æ¶ˆæ¯ + ä¿ç•™çš„æ–°æ¶ˆæ¯
        messages_to_summarize = messages[:-self.keep_recent]
        messages_to_keep = messages[-self.keep_recent:]

        logger.info(f"ğŸ“ [å¯¹è¯æ€»ç»“] æ€»ç»“ {len(messages_to_summarize)} æ¡æ—§æ¶ˆæ¯ï¼Œä¿ç•™ {len(messages_to_keep)} æ¡æ–°æ¶ˆæ¯")

        # å¦‚æœæ²¡æœ‰é…ç½® LLMï¼Œä½¿ç”¨ç®€å•å‹ç¼©
        if not self.llm:
            summary = self._simple_summary(messages_to_summarize)
        else:
            summary = self._llm_summary(messages_to_summarize)

        # åˆ›å»ºæ€»ç»“æ¶ˆæ¯
        summary_message = SystemMessage(
            content=f"""## ğŸ“ å†å²å¯¹è¯æ€»ç»“

ä»¥ä¸‹æ˜¯ä¹‹å‰ {len(messages_to_summarize)} æ¡æ¶ˆæ¯çš„æ€»ç»“ï¼š

{summary}

---
*æ­¤æ€»ç»“ç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œå‹ç¼©äº† {len(messages_to_summarize)} æ¡å†å²æ¶ˆæ¯*
"""
        )

        # è¿”å›ï¼šæ€»ç»“ + æœ€è¿‘çš„æ¶ˆæ¯
        result_messages = [summary_message] + messages_to_keep

        # è®°å½• token èŠ‚çœï¼ˆä¼°ç®—ï¼‰
        original_tokens = self._estimate_tokens(messages_to_summarize)
        summary_tokens = self._estimate_tokens([summary_message])
        tokens_saved = original_tokens - summary_tokens

        self.total_tokens_saved += tokens_saved

        logger.info(f"ğŸ’° [å¯¹è¯æ€»ç»“] ä¼°ç®—èŠ‚çœ {tokens_saved} tokens")

        return result_messages

    def _simple_summary(self, messages: List[BaseMessage]) -> str:
        """
        ç®€å•æ€»ç»“ï¼ˆä¸ä½¿ç”¨ LLMï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        summary_parts = []

        for i, msg in enumerate(messages):
            role = self._get_role_name(msg)
            content_preview = msg.content[:100] if msg.content else ""

            summary_parts.append(f"{i+1}. **{role}**: {content_preview}...")

        return "\n".join(summary_parts)

    def _llm_summary(self, messages: List[BaseMessage]) -> str:
        """
        ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ€»ç»“

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ€»ç»“æ–‡æœ¬
        """
        logger.info(f"ğŸ¤– [å¯¹è¯æ€»ç»“] ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ€»ç»“")

        # æ„å»ºå¯¹è¯å†å²æ–‡æœ¬
        conversation_text = self._format_conversation(messages)

        # æ€»ç»“æç¤ºè¯
        summary_prompt = f"""è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯å†å²ï¼Œä¿ç•™å…³é”®ä¿¡æ¯å’Œå†³ç­–è¦ç‚¹ï¼š

{conversation_text}

è¯·æä¾›ç®€æ´çš„æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
1. è®¨è®ºçš„ä¸»è¦è‚¡ç¥¨å’Œä¸»é¢˜
2. é‡è¦çš„åˆ†æç»“è®º
3. å…³é”®çš„æŠ•èµ„å»ºè®®
4. ä»»ä½•é‡è¦çš„é£é™©æç¤º

æ€»ç»“åº”æ§åˆ¶åœ¨200-300å­—ä»¥å†…ã€‚
"""

        try:
            # è°ƒç”¨ LLM
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=summary_prompt)])

            summary = response.content

            logger.info(f"âœ… [å¯¹è¯æ€»ç»“] LLM æ€»ç»“å®Œæˆ")
            return summary

        except Exception as e:
            logger.error(f"âŒ [å¯¹è¯æ€»ç»“] LLM æ€»ç»“å¤±è´¥: {e}")
            logger.warning(f"âš ï¸ [å¯¹è¯æ€»ç»“] å›é€€åˆ°ç®€å•æ€»ç»“")
            return self._simple_summary(messages)

    def _format_conversation(self, messages: List[BaseMessage]) -> str:
        """
        æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæ–‡æœ¬

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯æ–‡æœ¬
        """
        lines = []

        for msg in messages:
            role = self._get_role_name(msg)
            content = msg.content if msg.content else "[empty]"

            lines.append(f"{role}: {content}")
            lines.append("-" * 40)

        return "\n".join(lines)

    def _get_role_name(self, message: BaseMessage) -> str:
        """è·å–æ¶ˆæ¯è§’è‰²åç§°"""
        if isinstance(message, HumanMessage):
            return "ç”¨æˆ·"
        elif isinstance(message, AIMessage):
            return "AIåŠ©æ‰‹"
        elif isinstance(message, SystemMessage):
            return "ç³»ç»Ÿ"
        else:
            return "å…¶ä»–"

    def _estimate_tokens(self, messages: List[BaseMessage]) -> int:
        """
        ä¼°ç®—æ¶ˆæ¯çš„ token æ•°é‡

        ç®€å•ä¼°ç®—ï¼šä¸­æ–‡ 1å­— â‰ˆ 2 tokensï¼Œè‹±æ–‡ 1è¯ â‰ˆ 1.3 tokens
        æ›´ç²¾ç¡®çš„æ–¹æ³•åº”ä½¿ç”¨ tiktoken

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            ä¼°ç®—çš„ token æ•°
        """
        total_chars = sum(len(msg.content) if msg.content else 0 for msg in messages)

        # ç®€åŒ–ä¼°ç®—ï¼šå¹³å‡ 1.5 tokens per character
        estimated_tokens = int(total_chars * 1.5)

        return estimated_tokens

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        base_stats = super().get_stats()
        base_stats.update({
            "summarize_count": self.summarize_count,
            "total_tokens_saved": self.total_tokens_saved,
            "avg_tokens_saved_per_summary": (
                self.total_tokens_saved / self.summarize_count
                if self.summarize_count > 0 else 0
            )
        })
        return base_stats


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

"""
from langchain_openai import ChatOpenAI
from tradingagents.middleware.conversation_summary import ConversationSummaryMiddleware
from tradingagents.middleware.base import MiddlewareChain

# åˆ›å»º LLMï¼ˆç”¨äºæ™ºèƒ½æ€»ç»“ï¼‰
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 1. ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ€»ç»“
summary_middleware = ConversationSummaryMiddleware(
    llm=llm,
    max_messages=20,        # æœ€å¤šä¿ç•™20æ¡æ¶ˆæ¯
    keep_recent=5,          # å§‹ç»ˆä¿ç•™æœ€è¿‘5æ¡
    summarize_every=10      # æ¯10æ¡è§¦å‘æ€»ç»“
)

# 2. ä¸ä½¿ç”¨ LLMï¼ˆç®€å•å‹ç¼©ï¼‰
summary_middleware = ConversationSummaryMiddleware(
    llm=None,               # ä¸ä½¿ç”¨ LLM
    max_messages=15,
    keep_recent=3
)

# 3. ç»„åˆä½¿ç”¨å¤šä¸ªä¸­é—´ä»¶
from tradingagents.middleware.risk_control import RiskControlMiddleware
from tradingagents.middleware.human_approval import HumanApprovalMiddleware

chain = MiddlewareChain()
chain.add(ConversationSummaryMiddleware(llm=llm, max_messages=20))  # å¯¹è¯å‹ç¼©
chain.add(RiskControlMiddleware(risk_threshold=0.85))               # é£é™©æ§åˆ¶
chain.add(HumanApprovalMiddleware(approval_method=ApprovalMethod.CLI))  # äººå·¥å®¡æ‰¹

# åº”ç”¨åˆ°agent
wrapped_agent = chain.apply(original_agent_fn)

# æ‰§è¡Œåˆ†æï¼ˆé•¿å¯¹è¯ä¼šè‡ªåŠ¨æ€»ç»“ï¼‰
result = wrapped_agent(state)

# æŸ¥çœ‹ç»Ÿè®¡
stats = summary_middleware.get_stats()
print(f"æ€»ç»“æ¬¡æ•°: {stats['summarize_count']}")
print(f"èŠ‚çœ tokens: {stats['total_tokens_saved']}")
print(f"å¹³å‡æ¯æ¬¡èŠ‚çœ: {stats['avg_tokens_saved_per_summary']:.0f} tokens")
"""
